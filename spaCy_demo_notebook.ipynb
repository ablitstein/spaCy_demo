{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spaCy's English analyzer and the location where data is stored\n",
    "from spacy.en import English, LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's the English object all about?\n",
    "English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up spaCy NLP analyzer\n",
    "nlp_analyzer = English(data_dir=LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How does one interact with the analyzer object?\n",
    "nlp_analyzer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# The analyzer expects as input text -- the output contains all types of analysis\n",
    "# (parsing, tagging, and entity recognition can be turned off by setting them to\n",
    "# False)\n",
    "# Here's some input text that we'll use:\n",
    "sentences = \"\"\"This is a very simple sentence.\n",
    "This sentence, which is moderately more complex, is still quite simple.\n",
    "The two preceding sentences are easy to understand, hopefully easy to parse too.\n",
    "These sentences will be correctly parsed and tokenized if the gods look favorably on this demo.\n",
    "I hope that strange words like vapidity and celerity don't confuse the analyser (nor British spellings).\n",
    "One would even hopes that ungrammatical sentences not effects the parsing drammatically.\"\"\"\n",
    "\n",
    "# Let's analyze it and also get a sense for how long it takes for a text of this\n",
    "# size to be analyzed\n",
    "%timeit nlp_analyzer(sentences)\n",
    "analyzed_sentences = nlp_analyzer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at what's in the output\n",
    "# FYI, the output is automatically divided up into the constituent sentences and\n",
    "# the sentences are composed of constituent tokens, all of which can be\n",
    "# referenced simply by indices on the output object\n",
    "analyzed_sentence = analyzed_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzed_sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
