{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spaCy's English analyzer and the location where data is stored\n",
    "import pandas as pd\n",
    "from spacy.en import English, LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's the English object all about?\n",
    "English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up spaCy NLP analyzer (tokenizer, parser, NER-er, etc.)\n",
    "nlp_analyzer = English(data_dir=LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How does one interact with the analyzer object?\n",
    "nlp_analyzer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.21 ms per loop\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The analyzer expects as input text -- the output contains all types of analysis\n",
    "(parsing, tagging, and entity recognition can be turned off by setting them to\n",
    "False)\n",
    "\n",
    "Here's some input text that we'll use:\n",
    "\"\"\"\n",
    "text = [\"This is a very simple sentence.\",\n",
    "        \"This sentence, which is moderately more complex, is still quite simple.\",\n",
    "        \"The two preceding sentences are easy to understand, hopefully easy to parse too.\",\n",
    "        \"These sentences will be correctly parsed and tokenized if the gods look favorably on this demo.\",\n",
    "        \"I hope that strange words like vapidity and celerity don't confuse the analyser (nor British spellings).\",\n",
    "        \"One would even hopes that ungrammatical sentences not effects the parsing drammatically.\"]\n",
    "text = ' '.join(text)\n",
    "\n",
    "\"\"\"\n",
    "Let's analyze it and also get a sense for how long it takes for a text of this size\n",
    "to be analyzed\n",
    "\"\"\"\n",
    "%timeit nlp_analyzer(text)\n",
    "analyzed_text = nlp_analyzer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzed_text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a very simple sentence.\n",
      "\n",
      "This sentence, which is moderately more complex, is still quite simple.\n",
      "\n",
      "The two preceding sentences are easy to understand, hopefully easy to parse too.\n",
      "\n",
      "These sentences will be correctly parsed and tokenized if the gods look favorably on this demo.\n",
      "\n",
      "I hope that strange words like vapidity and celerity don't confuse the analyser (nor British spellings).\n",
      "\n",
      "One would even hopes that ungrammatical sentences not effects the parsing drammatically.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's take a look at what's in the output\n",
    "\n",
    "The output is automatically divided up into the constituent sentences (.sents\n",
    "attribute) and the sentences and text are composed of constituent tokens\n",
    "\"\"\"\n",
    "for sent in analyzed_text.sents:\n",
    "    print('{}\\n'.format(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The .sents attribute is a generator and it stores the objects corresponding to each\n",
    "recognized sentence\n",
    "\"\"\"\n",
    "sent = next(analyzed_text.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Each sentence is of type spacy.tokens.span.Span, which is basically just a sequence\n",
    "of token objects (more on that later)\n",
    "\n",
    "Here you can see the type of the objects\n",
    "\"\"\"\n",
    "type(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .string or .orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a very simple sentence.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To get the string representation of anything (not just a sentence object), i.e., the\n",
    "original token, the original sentence, the lemma, etc., use the .string or .orth_\n",
    "attributes\n",
    "\"\"\"\n",
    "sent.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a very simple sentence. '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .string attribute contains whitespace\n",
    "sent.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous String Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .is_alpha, .is_oov, .is_space, .like_email, .is_title, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASCII</th>\n",
       "      <th>OOV</th>\n",
       "      <th>Token</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>like_email</th>\n",
       "      <th>like_number</th>\n",
       "      <th>like_url</th>\n",
       "      <th>lower</th>\n",
       "      <th>lowercased</th>\n",
       "      <th>prefix</th>\n",
       "      <th>punct</th>\n",
       "      <th>shape</th>\n",
       "      <th>space</th>\n",
       "      <th>stop</th>\n",
       "      <th>suffix</th>\n",
       "      <th>titlecase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>This</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>this</td>\n",
       "      <td>T</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>his</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is</td>\n",
       "      <td>i</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>very</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>very</td>\n",
       "      <td>v</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ery</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>simple</td>\n",
       "      <td>s</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ple</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sentence</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>sentence</td>\n",
       "      <td>s</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>nce</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ASCII    OOV     Token  digit letter like_email like_number like_url  lower  \\\n",
       "0  True  False      This  False   True      False       False    False  False   \n",
       "1  True  False        is  False   True      False       False    False   True   \n",
       "2  True  False         a  False   True      False       False    False   True   \n",
       "3  True  False      very  False   True      False       False    False   True   \n",
       "4  True  False    simple  False   True      False       False    False   True   \n",
       "5  True  False  sentence  False   True      False       False    False   True   \n",
       "6  True  False         .  False  False      False       False    False  False   \n",
       "\n",
       "  lowercased prefix  punct shape  space   stop suffix titlecase  \n",
       "0       this      T  False  Xxxx  False   True    his      True  \n",
       "1         is      i  False    xx  False   True     is     False  \n",
       "2          a      a  False     x  False   True      a     False  \n",
       "3       very      v  False  xxxx  False   True    ery     False  \n",
       "4     simple      s  False  xxxx  False  False    ple     False  \n",
       "5   sentence      s  False  xxxx  False  False    nce     False  \n",
       "6          .      .   True     .  False  False      .     False  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Various pieces of information can be collected about each object representing a\n",
    "token.\n",
    "\"\"\"\n",
    "lines = []\n",
    "for token in sent:\n",
    "    lines.append(dict(Token=token.orth_, letter=token.is_alpha, ASCII=token.is_ascii,\n",
    "                      digit=token.is_digit, lower=token.is_lower, OOV=token.is_oov,\n",
    "                      punct=token.is_punct, space=token.is_space, stop=token.is_stop,\n",
    "                      titlecase=token.is_title, like_email=token.like_email,\n",
    "                      like_number=token.like_num, like_url=token.like_url,\n",
    "                      shape=token.shape_, prefix=token.prefix_, suffix=token.suffix_,\n",
    "                      lowercased=token.lower_))\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .doc attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a very simple sentence. This sentence, which is moderately more complex, is still quite simple. The two preceding sentences are easy to understand, hopefully easy to parse too. These sentences will be correctly parsed and tokenized if the gods look favorably on this demo. I hope that strange words like vapidity and celerity don't confuse the analyser (nor British spellings). One would even hopes that ungrammatical sentences not effects the parsing drammatically."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "If you want the whole document that the sentence occurred in, use the .doc attribute.\n",
    "\"\"\"\n",
    "sent.doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this be a very simple sentence .'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A lemmatized version of the object can be accessed via the .lemma_ attribute\n",
    "\"\"\"\n",
    "sent.lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simple</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token part_of_speech  tag\n",
       "0      This            DET   DT\n",
       "1        is           VERB  VBZ\n",
       "2         a            DET   DT\n",
       "3      very            ADV   RB\n",
       "4    simple            ADJ   JJ\n",
       "5  sentence           NOUN   NN\n",
       "6         .          PUNCT    ."
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for token in sent:\n",
    "    tokens.append(dict(Token=token.orth_, tag=token.tag_, part_of_speech=token.pos_))\n",
    "pd.DataFrame(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = This is a very simple sentence.\n",
      "root of sentence = is \n"
     ]
    }
   ],
   "source": [
    "print(\"sentence = {}\".format(sent.orth_))\n",
    "print(\"root of sentence = {}\".format(sent.root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .children, .dep_ attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = This is a very simple sentence.\n",
      "token: is \n",
      "children: [This , sentence, . ]\n",
      "head: is \n",
      "dependency relationship: ROOT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse tree-related attributes can be accessed for each token, such as the\n",
    "children/parents of the token, the dependency relationships, etc.\n",
    "\"\"\"\n",
    "token = sent[1]\n",
    "print(\"sentence = {}\".format(sent.orth_))\n",
    "print(\"token: {}\".format(token))\n",
    "print(\"children: {}\".format(list(token.children)))\n",
    "print(\"head: {}\".format(token.head))\n",
    "print(\"dependency relationship: {}\".format(token.dep_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Representation Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .repvec, .has\\_vector, .similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One would even hopes that ungrammatical sentences not effects the parsing drammatically.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Representing words as vectors allows for similarity calculations.\n",
    "\"\"\"\n",
    "last_sentence = list(analyzed_text.sents)[-1]\n",
    "last_sentence.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ungrammatical "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = last_sentence[5]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does this token have a vector?\n",
    "token1.has_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11843595, -0.06623109,  0.04538647,  0.02884347, -0.01294969,\n",
       "       -0.0082486 , -0.0888363 , -0.00583113,  0.00400044, -0.04227782,\n",
       "        0.12704024,  0.0674548 , -0.05201958, -0.01820735,  0.01730199,\n",
       "       -0.06442036, -0.10153879, -0.11339349,  0.04282263, -0.03628189,\n",
       "        0.01757631, -0.08853921,  0.05862839, -0.06814495,  0.03264917,\n",
       "        0.10444937,  0.00236884, -0.11556426,  0.08706038,  0.00214826,\n",
       "        0.00678102, -0.02899291, -0.03419275,  0.03446937, -0.01230073,\n",
       "        0.01153022, -0.01424529,  0.00808482, -0.02617856,  0.1339121 ,\n",
       "        0.02390695,  0.03199203,  0.03178117, -0.06182787,  0.01291667,\n",
       "        0.00363886,  0.04186788,  0.01629478, -0.05109784,  0.05638494,\n",
       "       -0.05947157, -0.03952258,  0.06754078, -0.04384648, -0.06870665,\n",
       "        0.15238763,  0.10236482, -0.12464427,  0.06899939, -0.04538237,\n",
       "       -0.03409704,  0.02009485, -0.05656509, -0.02657468,  0.0268659 ,\n",
       "       -0.00144608, -0.0471281 , -0.05084553,  0.03195825,  0.02315462,\n",
       "        0.03693955,  0.00735603, -0.03795239,  0.05013797,  0.06225931,\n",
       "        0.00652769,  0.07985584,  0.02860293, -0.01422559, -0.02713664,\n",
       "        0.12092071, -0.11951149,  0.07122544,  0.1519278 ,  0.0002385 ,\n",
       "        0.06619348, -0.12552635,  0.06724675, -0.02149052,  0.06398662,\n",
       "       -0.03640805, -0.04899743,  0.06755332, -0.06832408,  0.03138863,\n",
       "       -0.0217413 ,  0.01420179,  0.03834494,  0.01286831,  0.02829201,\n",
       "       -0.02811263, -0.07731683,  0.00906798, -0.07685211,  0.01106347,\n",
       "       -0.01278412, -0.05176266,  0.08916308,  0.00763112, -0.02492133,\n",
       "        0.15676528,  0.0098129 ,  0.06280617,  0.03315048, -0.03240428,\n",
       "       -0.0231843 ,  0.13899806,  0.01243124, -0.02915797,  0.14090578,\n",
       "       -0.00806384,  0.05345107,  0.10403379, -0.00736882,  0.05589515,\n",
       "        0.0313679 ,  0.02265024,  0.07873629,  0.00462662, -0.07629707,\n",
       "       -0.05948871, -0.01588048, -0.00841058, -0.00447744,  0.08713817,\n",
       "       -0.04144974, -0.00360713,  0.00747169, -0.00318515, -0.07251798,\n",
       "        0.04756364, -0.00375632, -0.05644763,  0.03722923,  0.09269574,\n",
       "        0.10891196, -0.01204893,  0.00731687, -0.08371631,  0.02170393,\n",
       "       -0.07229305,  0.07142684,  0.024462  , -0.04021196, -0.07980722,\n",
       "        0.08993461,  0.0021196 , -0.0695291 ,  0.00303955, -0.00890472,\n",
       "        0.02292405,  0.06455293, -0.0909925 ,  0.10832416, -0.09155547,\n",
       "       -0.06297711, -0.01820198, -0.01751515, -0.07483974, -0.00324683,\n",
       "       -0.04256136,  0.05231489, -0.14533792, -0.04048245, -0.02794373,\n",
       "       -0.00971335,  0.00853008, -0.00416473,  0.01021107, -0.05166874,\n",
       "       -0.02646055,  0.01819021,  0.08059794,  0.00256409, -0.05978402,\n",
       "       -0.02430743, -0.08025709,  0.06569627,  0.12786168, -0.00277111,\n",
       "       -0.00513381,  0.09923085,  0.02523046, -0.0771661 , -0.07763107,\n",
       "       -0.04362743,  0.0129873 , -0.0135014 , -0.08407123, -0.08689608,\n",
       "       -0.03349441, -0.02160874,  0.09388925,  0.06158938,  0.04756825,\n",
       "        0.01645574,  0.03193829,  0.02579829,  0.08704272,  0.05621911,\n",
       "        0.07978316, -0.04929197,  0.08103859, -0.0346485 , -0.01877928,\n",
       "       -0.05750756,  0.01630604, -0.01184216,  0.02510583, -0.02490393,\n",
       "        0.00123419,  0.02136078,  0.04909416,  0.0095007 ,  0.01039378,\n",
       "        0.02605214, -0.03232879, -0.11735581, -0.04740677,  0.09701606,\n",
       "       -0.0283849 ,  0.02891666, -0.0412202 , -0.0856317 , -0.01079861,\n",
       "        0.00438787,  0.04017153,  0.08363391, -0.03888284,  0.03944325,\n",
       "       -0.00732609,  0.01051354, -0.09530181,  0.00274578, -0.00319795,\n",
       "       -0.00022724, -0.01920945, -0.07281534, -0.07451424,  0.01772422,\n",
       "        0.03447961, -0.05227113,  0.01190204,  0.02860625,  0.05447133,\n",
       "       -0.06433336, -0.0587415 , -0.04402484, -0.00788676, -0.04113345,\n",
       "        0.01197062,  0.0012237 , -0.04307443, -0.0172114 ,  0.00464505,\n",
       "        0.1201868 , -0.07246731, -0.055368  , -0.0405825 , -0.07601098,\n",
       "        0.02253534, -0.00456802, -0.0546891 ,  0.01375192,  0.05443756,\n",
       "       -0.01132909,  0.06166282, -0.08045669, -0.04023321, -0.05966426,\n",
       "       -0.00796788, -0.10403226,  0.0295042 ,  0.02045029,  0.05120711,\n",
       "        0.04610068,  0.06248041, -0.02558692, -0.00307896, -0.10087576,\n",
       "        0.00308356, -0.00265033, -0.00718662, -0.06674264, -0.00665128,\n",
       "       -0.10113549, -0.03432863,  0.08222827,  0.03742627, -0.0638492 ], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.repvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentences "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = last_sentence[6]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3955893739185366"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How similar are \"ungrammatical\" and \"sentences\"?\n",
    "token1.similarity(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effects "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How similar are two random other words?\n",
    "token3 = last_sentence[8]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "would "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token4 = last_sentence[1]\n",
    "token4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23203454697543943"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3.similarity(token4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The similarity value is not as off as one might think, but it's still less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Probabilities and Brown Cluster IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .prob, .cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: This\n",
      "log probability: -6.78391695022583\n",
      "Brown cluster id: 382\n",
      "----------------------------------------\n",
      "original: is\n",
      "log probability: -4.457748889923096\n",
      "Brown cluster id: 762\n",
      "----------------------------------------\n",
      "original: a\n",
      "log probability: -3.92978835105896\n",
      "Brown cluster id: 19\n",
      "----------------------------------------\n",
      "original: very\n",
      "log probability: -6.93242883682251\n",
      "Brown cluster id: 234\n",
      "----------------------------------------\n",
      "original: simple\n",
      "log probability: -9.069649696350098\n",
      "Brown cluster id: 551\n",
      "----------------------------------------\n",
      "original: sentence\n",
      "log probability: -10.146957397460938\n",
      "Brown cluster id: 14309\n",
      "----------------------------------------\n",
      "original: .\n",
      "log probability: -3.0678977966308594\n",
      "Brown cluster id: 8\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(sent):\n",
    "    print(\"original:\", token.orth_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .ents, .ent\\_label, .ent\\_type_, .ent\\_iob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(two, British)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of the entities directly with .ents\n",
    "analyzed_text.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two CARDINAL\n",
      "British NORP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print out all of the tokens in the example text only if they\n",
    "# are entities\n",
    "[print(token.orth_, token.ent_type_)\n",
    " for token in analyzed_text\n",
    " if token.ent_type_ != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can Handle Messy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol NOUN lol\n",
      "that ADJ that\n",
      "is VERB be\n",
      "rly ADV rly\n",
      "funny ADJ funny\n",
      ":) PUNCT :)\n",
      "This DET this\n",
      "is VERB be\n",
      "gr8 VERB gr8\n",
      "i NOUN i\n",
      "rate VERB rate\n",
      "it NOUN it\n",
      "8/8 NUM 8/8\n",
      "! PUNCT !\n",
      "! PUNCT !\n",
      "! PUNCT !\n"
     ]
    }
   ],
   "source": [
    "messy_data = \"lol that is rly funny :) This is gr8 i rate it 8/8!!!\"\n",
    "analyzed_messy_data = nlp_analyzer(messy_data)\n",
    "for token in analyzed_messy_data:\n",
    "    print(token.orth_, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297484"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vocabulary that the analyzer uses can be accessed and used (and\n",
    "# also it, along with almost every other component of the system, can\n",
    "# be customized)\n",
    "vocab = nlp_analyzer.vocab\n",
    "vocab.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If there's a word that's in the vocabulary, then it can be loaded in and\n",
    "# interacted with\n",
    "vapid = vocab['vapid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68950913894393639"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vapid.similarity(vocab['senseless'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 closest results for king - man + woman:\n",
      "\n",
      "\tqueen\n",
      "\tmonarch\n",
      "\tprincess\n"
     ]
    }
   ],
   "source": [
    "# Credit: https://nicschrading.com/project/Intro-to-NLP-with-spaCy/\n",
    "# Let's see if it can figure out this analogy\n",
    "# Man is to King as Woman is to ??\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Cosine similarity\n",
    "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "king = nlp_analyzer.vocab['king']\n",
    "man = nlp_analyzer.vocab['man']\n",
    "woman = nlp_analyzer.vocab['woman']\n",
    "\n",
    "result = king.repvec - man.repvec + woman.repvec\n",
    "\n",
    "# Gather all known words, take only the lowercased versions\n",
    "all_words = list({w for w in nlp_analyzer.vocab\n",
    "                  if w.has_vector\n",
    "                     and w.orth_.islower()\n",
    "                     and w.lower_ != \"king\"\n",
    "                     and w.lower_ != \"man\"\n",
    "                     and w.lower_ != \"woman\"})\n",
    "\n",
    "# Sort by similarity to the result\n",
    "all_words.sort(key=lambda w: cosine(w.repvec, result))\n",
    "all_words.reverse()\n",
    "print(\"Top 3 closest results for king - man + woman:\\n\")\n",
    "for word in all_words[:3]:   \n",
    "    print(\"\\t{}\".format(word.orth_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most of the methods/attributes that we've been using can also be used in\n",
    "# \"standalone\" mode and further attributes of the analyzer object can be\n",
    "# specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analyzer.like_email(\"mulhodm@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"\"',\n",
       " '#',\n",
       " '$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'BES',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'GW',\n",
       " 'HVS',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NIL',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '``')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analyzer.tagger.tag_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources, Links to Guides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [spaCy home page](https://spacy.io/) - [tutorials section](http://spacy.io/docs/#tutorials)\n",
    "## 2. [Nic Schrading's Intro to NLP with spaCy](https://nicschrading.com/project/Intro-to-NLP-with-spaCy/), a fantastic guide (which I stole from a little)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
